{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data for Database\n",
    "In this notebook, we pre-process the three primary tables we plan to utilize for our application:\n",
    "1. Album of The Year critic ratings\n",
    "- Features user and critic review aggregated by Album of the Year and Metacritic\n",
    "- The dataset includes more than 30K rows of albums and aggregated critic and user review scores\n",
    "- Link to source https://www.kaggle.com/kauvinlucas/30000-albums-aggregated-review-ratings\n",
    "\n",
    "2. Spotify API\n",
    "- More than 1.2M songs collected from Spotifyâ€™s API\n",
    "- The dataset includes features like name, artists, album, release date, key, explicit flag, duration, popularity, danceability, and more\n",
    "- The data was created in December 2020. Each row represents a single track\n",
    "- Link to source https://www.kaggle.com/rodolfofigueroa/spotify-12m-songs\n",
    "\n",
    "3. Pitchfork reviews\n",
    "- Includes over 18K Pitchfork (an online music magazine) review going back to January 1999\n",
    "- The database contains separate tables on artists, content, genres, labels, reviews, and years\n",
    "- Link to source https://www.kaggle.com/nolanbconaway/pitchfork-data\n",
    "\n",
    "The notebook will read in the datasets, process, and output the final datasets in csv that will ultimately be uploaded to AWS RDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AOTY Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "df_ratings = pd.read_csv('./album_ratings.csv') # Metacritic/AOTY\n",
    "\n",
    "print(df_ratings.shape)\n",
    "df_ratings.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "df_spotify = pd.read_csv('./tracks_features.csv') #Spotify/Kaggle 1.2M tracks\n",
    "print(df_spotify.shape)\n",
    "df_spotify.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pitchfork reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"./database.sqlite\")\n",
    "\n",
    "# Read\n",
    "query_str = \\\n",
    "\"\"\"\n",
    "SELECT \n",
    "    t1.reviewid\n",
    "    , t1.title\n",
    "    , t1.artist\n",
    "    , t1.url\n",
    "    , t1.score\n",
    "    , t1.author\n",
    "    , t1.pub_date\n",
    "    , t1.best_new_music\n",
    "    , t2.content\n",
    "    \n",
    "FROM reviews t1 JOIN content t2 ON t1.reviewid = t2.reviewid\n",
    "\"\"\"\n",
    "\n",
    "df_pitchfork = pd.read_sql_query(query_str, con)\n",
    "con.close()\n",
    "\n",
    "print(df_pitchfork.shape)\n",
    "df_pitchfork.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All datasets: Select only the columns we need, rename fields, and create a lowercased version of the album and artist\n",
    "The lowercased album and artist will help joins across the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOTY\n",
    "df_ratings = df_ratings[[\n",
    "    'Artist'\n",
    "    , 'Title'\n",
    "    , 'Format'\n",
    "    , 'Label'\n",
    "    , 'Genre'\n",
    "    , 'AOTY Critic Score'\n",
    "    , 'AOTY Critic Reviews'\n",
    "    , 'AOTY User Score'\n",
    "    , 'AOTY User Reviews'  \n",
    "]].copy()\n",
    "df_ratings = df_ratings.rename(columns={\"Title\": \"album_name\", \"Artist\": \"artist\"})\n",
    "df_ratings['album_name_lc'] = df_ratings['album_name'].str.lower()\n",
    "df_ratings['artist_lc'] = df_ratings['artist'].str.lower()\n",
    "\n",
    "# Spotify\n",
    "# Select all columns for this dataset\n",
    "df_spotify = df_spotify.rename(\n",
    "                            columns={\"id\": \"track_id\"\n",
    "                                     , \"name\": \"track_name\"\n",
    "                                     , \"album\": \"album_name\"\n",
    "                                     , \"artists\": \"artist\"\n",
    "                                    })\n",
    "df_spotify['album_name_lc'] = df_spotify['album_name'].str.lower()\n",
    "df_spotify['artist_lc'] = df_spotify['artist'].str.lower()\n",
    "\n",
    "# Pitchfork\n",
    "df_pitchfork = df_pitchfork.rename(\n",
    "                                columns={\n",
    "                                    \"title\": \"album_name\",\n",
    "                                    \"url\": \"pf_url\",\n",
    "                                    \"score\": \"pf_score\",\n",
    "                                    \"author\": \"pf_author\",\n",
    "                                    \"pub_date\": \"pf_pubdate\",\n",
    "                                    \"content\": \"pf_review\"\n",
    "                                })\n",
    "df_pitchfork['album_name_lc'] = df_pitchfork['album_name'].str.lower()\n",
    "df_pitchfork['artist_lc'] = df_pitchfork['artist'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spotify API: Parse out the first artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning Spotify artists\n",
    "def getFirstArtist(s):\n",
    "    '''\n",
    "    This function removes the list like structure of the \"artists\" field in the Spotify dataset. Pick the first artist in the list\n",
    "    \n",
    "    Input : List of artists (str)\n",
    "    Output: One artist (str)\n",
    "    '''\n",
    "    s = s.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    first_element = s.find(\",\")\n",
    "    return s[:first_element].replace(\"'\", \"\")\n",
    "\n",
    "# Clean\n",
    "df_spotify['artist'] = df_spotify['artist'].apply(lambda s:getFirstArtist(s))\n",
    "df_spotify['artist_lc'] = df_spotify['artist_lc'].apply(lambda s:getFirstArtist(s))\n",
    "df_spotify['artist_ids'] = df_spotify['artist_ids'].apply(lambda s:getFirstArtist(s))\n",
    "\n",
    "df_spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitchfork Reviews: Clean the album names so that future joins are more likely to match across the three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning Pitchfork album names\n",
    "def cleanPitchforkAlbumNames(s):\n",
    "    '''\n",
    "    This function sanitizes the album names in the Pitchfork dataset. The album names are rather specific, and will include details\n",
    "    like \"40th anniversary edition\". So let's remove that\n",
    "    \n",
    "    Input : A dirty album name (str)\n",
    "    Output: A clean album name (str)\n",
    "    '''\n",
    "    \n",
    "    # Remove anything in brackets. Usually this will denote the edition\n",
    "    bracket_check = s.find(\"[\")\n",
    "    if bracket_check != -1:\n",
    "        s = s[:bracket_check].strip()\n",
    "        \n",
    "    # Remove anything that comes after a \"n\"th annivesary edition using regex\n",
    "    nth_anniv_check = re.search(r'[0-9]+(th|st|nd|rd)', s)\n",
    "    if nth_anniv_check:\n",
    "        ix = nth_anniv_check.start()\n",
    "        s = s[:ix].strip(\": \")\n",
    "    \n",
    "    return s\n",
    "\n",
    "# Clean\n",
    "df_pitchfork['orig_album_name'] = df_pitchfork['album_name']\n",
    "df_pitchfork['album_name'] = df_pitchfork['album_name'].apply(lambda s:cleanPitchforkAlbumNames(s))\n",
    "\n",
    "# Check that PF album sanitation worked\n",
    "# 'album_name' is the sanitized field\n",
    "df_pitchfork.sort_values('pf_score', ascending = False)[['orig_album_name', 'album_name']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General EDA\n",
    "How many albums overlap between the three datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to only albums and artists\n",
    "t1 = df_ratings[['album_name_lc', 'artist_lc']].drop_duplicates()\n",
    "t2 = df_spotify[['album_name_lc', 'artist_lc']].drop_duplicates()\n",
    "t3 = df_pitchfork[['album_name_lc', 'artist_lc']].drop_duplicates()\n",
    "\n",
    "# How many unique albums are there in each dataset?\n",
    "# Albums with same name but different artist are counted as different\n",
    "print('How many unique albums are there in each dataset?')\n",
    "print('AOTY: ', len(t1))\n",
    "print('Spotify: ', len(t2))\n",
    "print('Pitchfork: ', len(t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres = pd.read_csv('./genres-revised.csv')\n",
    "df_genres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genres: Add Ids to Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to transform genres file and apply to ratings\n",
    "def rename_genres(genre):\n",
    "    for column in df_genres:\n",
    "        if genre in df_genres[column].values:\n",
    "            return column\n",
    "\n",
    "def genre_index(genre):\n",
    "    if genre in df_genres.columns:\n",
    "        return df_genres.columns.get_loc(genre)\n",
    "\n",
    "# narrow genre options for the ratings data\n",
    "df_ratings['Genre'] = df_ratings['Genre'].apply(lambda d: rename_genres(d))\n",
    "df_ratings['genre_id'] = df_ratings['Genre'].apply(lambda d: genre_index(d))\n",
    "\n",
    "df_ratings['genre_id'] = pd.to_numeric(df_ratings['genre_id'], downcast='integer')\n",
    "df_genre_id_column = pd.DataFrame(\n",
    "    {\n",
    "        \"genre_id\": pd.Series(df_ratings['genre_id'], dtype=np.dtype(\"int64\"))\n",
    "    }\n",
    ")\n",
    "df_genre_id_column = df_genre_id_column.convert_dtypes()\n",
    "df_ratings['genre_id'] = df_genre_id_column['genre_id']\n",
    "\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame({\"Label\": df_ratings['Label'].drop_duplicates()})\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_index(label):\n",
    "    for row in df_labels['Label']:\n",
    "        if row == label:\n",
    "            return df_labels.index[df_labels['Label'] == label][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels: Add Ids to Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings['label_id'] = df_ratings['Label'].apply(lambda d: label_index(d))\n",
    "\n",
    "df_label_id_column = pd.DataFrame(\n",
    "    {\n",
    "        \"label_id\": pd.Series(df_ratings['label_id'], dtype=np.dtype(\"int64\"))\n",
    "    }\n",
    ")\n",
    "df_label_id_column = df_label_id_column.convert_dtypes()\n",
    "df_ratings['label_id'] = df_label_id_column['label_id']\n",
    "\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset of All But Pitchfork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_spotify, df_ratings, on=['artist_lc', 'album_name_lc'])\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create .csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean master dataset before creating each of the normalized tables\n",
    "df_culled = df_merged.drop(columns=['album_name_x', 'artist_x', 'release_date']) \\\n",
    "            .rename(columns={\"album_name_y\": \"album_name\",\"artist_y\": \"artist\"})\n",
    "\n",
    "df_culled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to dedup albums, as some have multiple versions (explicit and clean)\n",
    "df_album = df_culled[[\n",
    "    'album_id'\n",
    "    , 'album_name'\n",
    "    , 'artist_ids'\n",
    "    , 'genre_id'\n",
    "    , 'label_id'\n",
    "    , 'year'\n",
    "    , 'Format'\n",
    "    , 'AOTY Critic Score'\n",
    "    , 'AOTY Critic Reviews'\n",
    "    , 'AOTY User Score'\n",
    "    , 'AOTY User Reviews']].drop_duplicates(subset = ['album_name', 'artist_ids'], keep = 'first')\n",
    "\n",
    "# Update master dataset by filtering for the deduped albums\n",
    "df_culled = df_culled[df_culled['album_id'].isin(df_album['album_id'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out and save seed tables\n",
    "df_album.to_csv('./seed/album.csv', index = False)\n",
    "df_culled[['artist', 'artist_ids']].drop_duplicates().to_csv('./seed/artist.csv', index = False)\n",
    "df_culled[['Genre', 'genre_id']].dropna().drop_duplicates().to_csv('./seed/genre.csv', index = False)\n",
    "df_culled[['Label', 'label_id']].dropna().drop_duplicates().to_csv('./seed/label.csv', index = False)\n",
    "df_culled[[\n",
    "    'track_id', 'track_name', 'album_id', 'disc_number'\n",
    "    , 'track_number', 'danceability', 'energy', 'key', 'loudness'\n",
    "    , 'mode', 'speechiness', 'acousticness', 'instrumentalness'\n",
    "    , 'liveness', 'valence', 'tempo', 'explicit', 'duration_ms', 'time_signature']] \\\n",
    "    .drop_duplicates().to_csv('./seed/song.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Reviews and Authors (from Pitchfork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_culled2 = pd.merge(\n",
    "    df_culled.drop_duplicates(subset = ['album_name', 'artist_ids'], keep = 'first')\n",
    "    , df_pitchfork\n",
    "    , on=['artist_lc', 'album_name_lc']\n",
    "    , how = 'inner')\n",
    "df_culled2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save seed table\n",
    "df_culled2 = df_culled2.reset_index().rename(columns = {'index': 'id'})\n",
    "df_culled2[['id', 'album_id', 'pf_url', 'pf_score', 'pf_pubdate']].to_csv('./review.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
